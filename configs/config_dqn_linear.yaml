run_name: "DQN_2048-v2"
algorithm: "dqn"
env: "2048-v1"
n_episodes: 1000000 #20000
seed: 1234
log_video: True
log_every: 10
save_every: 100
max_episode_steps: 1000
model_basedir: "./checkpoints"
model_ckpt: "./checkpoints/2048-v1/DQN_2048-v1/20230423040240/best_score.ckpt"

optimizer: "Adam"
learning_rate: 
  policy: 0.0001

discount: 0.99
eps_high: 0.9
eps_low: 0.05
eps_decay: 100000 #100000 #10000

reward_scale: "divide_10" #"divide_100" #divide_100 #"log" "naive" #linear was divide 100
batch_size: 2048
buffer_size: 1000000
start_size: 10000 #1000  #100
hidden_layer: 3
hidden_units: 256 #128 #I used 256 for 25bits/45bits and 128 for 10bits
architecture: "linear"
non_linearity: "ReLU"
target_smoothing_coefficient: 0.005
